{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Miscellaneous \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../archive/house_prices.csv\")\n",
    "# The 0 bedroom properties will be deleted, because it makes no sense a flat with 0 bedrooms. \n",
    "data = data.loc[data['bedrooms']!=0,].reset_index().drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'property_type', 'price', 'location', 'city', 'baths',\n",
       "       'purpose', 'bedrooms', 'Area_in_Marla'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = data.columns[[1, 3, 4, 5, 6, 7]]\n",
    "cont_data = data.columns[[2,8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard Scaler\n",
    "# Columns to scale: price, Area_in_Marla\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# data.update(np.asmatrix(scaler.fit_transform(data[cont_data])))\n",
    "\n",
    "data[cont_data] = pd.DataFrame(np.asmatrix(scaler.fit_transform(data[cont_data])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encoding\n",
    "# Columns to ohe: property_type, location, city, baths, bedrooms and purpose\n",
    "one_hot = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "cat_X = one_hot.fit_transform(data[cat_data])\n",
    "cat_X = pd.DataFrame(np.asmatrix(cat_X), index = data.index)\n",
    "cat_X.columns = one_hot.get_feature_names_out()\n",
    "\n",
    "data = pd.concat([data.drop(cat_data, axis = 1), cat_X], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('index', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'Area_in_Marla', 'property_type_Farm House',\n",
       "       'property_type_Flat', 'property_type_House',\n",
       "       'property_type_Lower Portion', 'property_type_Penthouse',\n",
       "       'property_type_Room', 'property_type_Upper Portion',\n",
       "       'location_12th Avenue',\n",
       "       ...\n",
       "       'baths_6', 'baths_7', 'purpose_For Rent', 'purpose_For Sale',\n",
       "       'bedrooms_1', 'bedrooms_2', 'bedrooms_3', 'bedrooms_4', 'bedrooms_5',\n",
       "       'bedrooms_6'],\n",
       "      dtype='object', length=1415)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train-Test split, multiple model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,1:], data.iloc[:,0], train_size=0.7, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the models and the hyperparameter configuration\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'GradientBoosting': GradientBoostingRegressor(),\n",
    "    'RandomForest': RandomForestRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'ElasticNet':{'alpha':[0.3, 0.6, 0.9], 'l1_ratio':[0.25, 0.5, 0.75], 'fit_intercept':[True, False], 'random_state':[1234]},\n",
    "    'LinearRegression':{'fit_intercept':[True, False]},\n",
    "    'GradientBoosting':{'learning_rate':[0.1, 0.001, 1], 'n_estimators':[50, 100, 200, 500], 'random_state':[1234], 'max_depth':[3, 6, 9], 'ccp_alpha':[0.1, 0.3, 0.5]},\n",
    "    'RandomForest':{'n_estimators':[50, 100, 200, 500], 'max_depth':[3, 6, 9], 'max_features': ['sqrt'], 'random_state':[1234], 'ccp_alpha':[0.1, 0.3, 0.5]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ElasticNet.\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Running GridSearchCV for LinearRegression.\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Running GridSearchCV for GradientBoosting.\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    }
   ],
   "source": [
    "helper1 = EstimatorSelectionHelper(models, parameters)\n",
    "results = []\n",
    "\n",
    "for j in ['neg_mean_absolute_percentage_error', 'r2', 'max_error']:\n",
    "    helper1.fit(X_train, y_train, scoring=j, n_jobs=4)\n",
    "    aux = helper1.score_summary(sort_by='max_score')\n",
    "    aux['metric'] = j\n",
    "    results.append(aux)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
